{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing using BeautifulSoup and GROBID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pytesseract\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fitz\n",
    "from matplotlib import pyplot as plt\n",
    "import io\n",
    "import os\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_bytes\n",
    "import pypdfium2 as pdfium\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCANNED_FILE = \"example.pdf\"\n",
    "img = cv2.imread(SCANNED_FILE)\n",
    "\n",
    "\n",
    "zoom_x = 2.0 # horizontal zoom\n",
    "zoom_y = 2.0 # vertical zoom\n",
    "mat = fitz.Matrix(zoom_x, zoom_y)\n",
    "\n",
    "doc = fitz.open(SCANNED_FILE)\n",
    "\n",
    "print(\"Generated pages: \")\n",
    "for page in doc:\n",
    "    pix = page.get_pixmap(matrix=mat)\n",
    "    png = 'C:\\\\Repositories\\\\Circuit_Benchmarking\\\\pages' + SCANNED_FILE.split('\\\\')[-1].split('.')[0] + 'page-%i.png' % page.number\n",
    "    print(png)\n",
    "    pix.save(png)\n",
    "\n",
    "original_image = cv2.imread('C:\\\\Repositories\\\\Circuit_Benchmarking\\\\pagesexamplepage-11.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "plt.figure(figsize=(25, 15))\n",
    "plt.imshow(gray_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, threshold_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "plt.figure(figsize=(25, 15))\n",
    "plt.imshow(threshold_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectangular_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (66, 66))\n",
    "\n",
    "# Applying dilation on the threshold image\n",
    "dilated_image = cv2.dilate(threshold_image, rectangular_kernel, iterations = 1)\n",
    "plt.figure(figsize=(25, 15))\n",
    "plt.imshow(dilated_image)\n",
    "plt.show()\n",
    "\n",
    "# Finding contours\n",
    "contours, hierarchy = cv2.findContours(dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Creating a copy of the image\n",
    "copied_image = original_image.copy()\n",
    "\n",
    "with open(\"C:\\\\Repositories\\\\Circuit_Benchmarking\\\\pages\\\\kernel66-66\", \"w+\") as f:\n",
    "    f.write(\"\")\n",
    "f.close()\n",
    "\n",
    "mask = np.zeros(original_image.shape, np.uint8)\n",
    " \n",
    "# Looping through the identified contours\n",
    "# Then rectangular part is cropped and passed on to pytesseract\n",
    "# pytesseract extracts the text inside each contours\n",
    "# Extracted text is then written into a text file\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "     \n",
    "    # Cropping the text block for giving input to OCR\n",
    "    cropped = copied_image[y:y + h, x:x + w]\n",
    "    \n",
    "    with open(\"C:\\\\Repositories\\\\Circuit_Benchmarking\\\\pages\\\\kernel66-66\", \"a\") as f:\n",
    "        # Apply OCR on the cropped image\n",
    "        text = pytesseract.image_to_string(cropped, lang='eng', config='--oem 3 --psm 1')\n",
    "        print(text)\n",
    "        \n",
    "    masked = cv2.drawContours(mask, [cnt], 0, (255, 255, 255), -1)\n",
    "\n",
    "plt.figure(figsize=(25, 15))\n",
    "plt.imshow(masked, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract tables from the TEI XML\n",
    "def extract_tables(tei_xml):\n",
    "    tables = []\n",
    "\n",
    "    soup = BeautifulSoup(tei_xml, 'lxml')\n",
    "    table_elems = soup.find_all('Table')\n",
    "\n",
    "    for table in table_elems:\n",
    "        rows = []\n",
    "        for row in table.find_all('row'):\n",
    "            cells = [cell.get_text(strip=True) for cell in row.find_all('cell')]\n",
    "            rows.append(cells)\n",
    "        tables.append(rows)\n",
    "\n",
    "    return tables\n",
    "\n",
    "# Set up GROBID service\n",
    "grobid_url = 'http://localhost:8070/api'\n",
    "headers = {'Accept': 'application/x-bibtex'}\n",
    "\n",
    "# Path to the PDF file\n",
    "pdf_path = \"C:\\Repositories\\Circuit_Benchmarking\\example.pdf\"\n",
    "\n",
    "# Path to the output text file\n",
    "output_file = \"C:\\Repositories\\Circuit_Benchmarking\\output_test.txt\"\n",
    "\n",
    "# Send PDF to GROBID service for processing\n",
    "with open(pdf_path, 'rb') as pdf:\n",
    "    response = requests.post(f'{grobid_url}/processFulltextDocument', files={'input': pdf_path})\n",
    "    tei_xml = response.text\n",
    "\n",
    "# Extract tables from GROBID output\n",
    "tables = extract_tables(tei_xml)\n",
    "\n",
    "# Process image using OpenCV\n",
    "original_image = cv2.imread('C:\\\\Repositories\\\\Circuit_Benchmarking\\\\pagesexamplepage-11.png')\n",
    "gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "threshold_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "\n",
    "rectangular_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (66, 66))\n",
    "dilated_image = cv2.dilate(threshold_image, rectangular_kernel, iterations=1)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "copied_image = original_image.copy()\n",
    "\n",
    "# Initialize the output text file\n",
    "with open(output_file, \"w+\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "mask = np.zeros(original_image.shape, np.uint8)\n",
    "\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    cropped = copied_image[y:y + h, x:x + w]\n",
    "\n",
    "    with open(output_file, \"a\") as f:\n",
    "        # Apply OCR on the cropped image\n",
    "        text = pytesseract.image_to_string(cropped, lang='eng', config='--oem 3 --psm 1')\n",
    "        f.write(text)\n",
    "\n",
    "    masked = cv2.drawContours(mask, [cnt], 0, (255, 255, 255), -1)\n",
    "\n",
    "# Append extracted tables to the output text file\n",
    "with open(output_file, \"a\") as f:\n",
    "    for table in tables:\n",
    "        for row in table:\n",
    "            f.write('\\t'.join(row))\n",
    "            f.write('\\n')\n",
    "        f.write('\\n')\n",
    "\n",
    "# Show the processed image\n",
    "plt.figure(figsize=(25, 15))\n",
    "plt.imshow(masked, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ones below work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "def get_two_columned_page(im1, im2):\n",
    "    page = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    page.paste(im1, (0, 0))\n",
    "    page.paste(im2, (0, im1.height))\n",
    "    return page\n",
    "\n",
    "pdf_images = convert_from_path(\"example.pdf\", 500, poppler_path=r'C:\\\\bin\\\\poppler-0.68.0\\\\bin')\n",
    "output_images = []\n",
    "\n",
    "for page_number, page_image in enumerate(pdf_images):\n",
    "    pil_image_1 = page_image.crop((0, 0, page_image.width // 2, page_image.height))\n",
    "    pil_image_2 = page_image.crop((page_image.width // 2, 0, page_image.width, page_image.height))\n",
    "\n",
    "    singular_page = get_two_columned_page(pil_image_1, pil_image_2)\n",
    "    singular_page.save(f\"image_{page_number+1}.png\")\n",
    "    output_images.append(singular_page)\n",
    "\n",
    "# Create a PDF from the saved images\n",
    "output_images[0].save(\"output.pdf\", \"PDF\", resolution=100.0, save_all=True, append_images=output_images[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# Update this path to your Tesseract installation path\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "\n",
    "# Convert the PDF file to a list of images\n",
    "pdf_images = convert_from_path(\"output.pdf\", poppler_path=r'C:\\\\bin\\\\poppler-0.68.0\\\\bin')\n",
    "\n",
    "# Extract text from each image in the list\n",
    "text = ''\n",
    "for page_num, page_image in enumerate(pdf_images):\n",
    "    page_text = pytesseract.image_to_string(page_image, lang=\"eng\")\n",
    "    text += page_text\n",
    "\n",
    "# Writes to an arbitrary text file \n",
    "with open('output.txt', 'w') as fp:\n",
    "    fp.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
